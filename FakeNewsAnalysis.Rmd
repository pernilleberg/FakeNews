---
title: "Analysis; The Spread of Fake News"
author: "Pernille Berg Lassen"
date: "28 apr 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

Analyzing the spread of Fake News in a Social Network.

Outline:
  1. Data cleaning 
  2. Plots/Visualizations
  3. Models used for analysis (brms)
  4. Plotting prior and posterior distributions
  5. Assessing model quality 
  

```{r}
library(pacman)
p_load(rethinking,brms,brmstools,ggplot2,caret,dplyr)


#Reading in Data and cleaning it
FN_df = read.csv("FakeNewsData3test1.csv", sep = ";")
FN_df$ID = 1
FN_df2 = read.csv("FakeNewsData3test2.csv", sep = ";")
FN_df2$ID = 2

dataset<-rbind(FN_df, FN_df2)

# Change column names
colnames(dataset) = c("runNumber", "nodesAmount", "outbreakSize", "numberofWD", "recovery", "tick", "turtlesAmount", "clusteringCoef", "pathLength", "naivesAmount", "spreadersAmount", "educatedAmount", "untouchedAmount", "fileID")

dataset$turtlesAmount = NULL

# blue ones = naives
# red = spreaders
# grey = educated
# yellow = untouched

dataset$runNumber = as.numeric(dataset$runNumber)



```

```{r}
#PLaying around with plots - some visualizations about development of agents over time

#Amount of spreaders over time when outbreak size is maximum
temp = subset(dataset, outbreakSize == "188")
temp$numberofWD = as.factor(temp$numberofWD)

ggplot(temp,aes(tick,spreadersAmount, color = numberofWD))+
  geom_point()+
  ggtitle("Outbreak Size = 188 (Max)")+
  theme_classic()

#Amount of spreaders over time when outbreak size is minimum
temp = subset(dataset, outbreakSize == "1")
temp$numberofWD = as.factor(temp$numberofWD)

ggplot(temp, aes(tick,spreadersAmount, color = numberofWD))+
  geom_point()+
  ggtitle("Outbreak Size = 1 (Min)")+
  theme_classic()

#Amount of spreaders over time when number of wd is minimum
temp = subset(dataset, numberofWD == "10")
temp$outbreakSize = as.factor(temp$outbreakSize)

ggplot(temp, aes(tick,spreadersAmount, color = outbreakSize))+
  geom_point()+
  ggtitle("Number of WD = 10 (Min)")+
  theme_classic()

#Amount of spreaders over time when number of wd is maximum
temp = subset(dataset, numberofWD == "50")
temp$outbreakSize = as.factor(temp$outbreakSize)

ggplot(temp, aes(tick,spreadersAmount, color = outbreakSize))+
  geom_point()+
  ggtitle("Number of WD = 50 (Max)")+
  theme_classic()

temp = dataset
temp$outbreakSize = as.factor(temp$outbreakSize)

#Agent development over time
ggplot(temp, aes(tick, untouchedAmount, color = outbreakSize))+
  geom_smooth()+
  facet_wrap(~outbreakSize)+
  theme_classic()

ggplot(temp, aes(tick, educatedAmount, color = outbreakSize))+
  geom_smooth()+
  facet_wrap(~outbreakSize)+
  theme_classic()

ggplot(temp, aes(tick, spreadersAmount, color = outbreakSize))+
  geom_smooth()+
  facet_wrap(~outbreakSize)+
  theme_classic()

ggplot(temp, aes(tick, naivesAmount, color = outbreakSize))+
  geom_smooth()+
  facet_wrap(~outbreakSize)+
  theme_classic()
```


```{r}
#Adding new columns:
dataset$Ratio_WD = dataset$numberofWD/dataset$nodesAmount #we expect an interaction between number of nodes and number of WD - using ratio in models instead 
dataset$ID_new = as.factor(paste(dataset$fileID, dataset$runNumber, sep = "_")) #making a new ID column which takes into account which fileID (some runNumbers are the same)

df <- arrange(dataset, ID_new)

#Summarize by maximum number of ticks so we know the ticks it took to complete each sim - our outcome
maxTick = group_by(df,ID_new) %>%
  summarize(maxTick = max(tick))
new_df=merge(df,maxTick, all = T)

rescalelist = c("outbreakSize","Ratio_WD", "clusteringCoef","pathLength")
new_df.s = new_df[, colnames(new_df) %in% rescalelist] %>% 
  lapply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,new_df[,! colnames(new_df) %in% rescalelist]) 

new_df.s2 = unique(new_df.s$ID_new)
new_df.s2 = group_by(new_df.s, ID_new, outbreakSize, Ratio_WD, maxTick,clusteringCoef, pathLength) %>%
  summarise_each(funs(mean(., na.rm = TRUE)), runNumber)

#Look at the outcome function - which likelihood function do we want?
  #Outcome is count - poisson 
dens(new_df.s2$maxTick)


#WatchDog model
m1_formula <- bf(maxTick ~ outbreakSize + Ratio_WD)

#get_prior(m1_formula,new_df) #Asking the model which priors it recommend

prior = c(prior(normal(log(9.2),log(4.8)), class = Intercept),
          prior(normal(0,0.5), class = b, coef = outbreakSize), 
          prior(normal(0,0.5), class = b, coef = Ratio_WD)) 


m1 <- brm(m1_formula,
          family = poisson(link = "log"), #We assume our likelihood function to be poisson
          prior = prior, #our list of pre-defined priors
          data = new_df.s2,
          warmup = 4000,
          iter = 10000,
          cores = 3,
          chain = 3)

summary(m1)
plot(m1)

#m1.1_formula <- bf(maxTick ~ outbreakSize + Ratio_WD + (outbreakSize + Ratio_WD|ID_new))
#m1.1 <- brm(m1.1_formula,
          #family = poisson(link = "log"), #We assume our likelihood function to be poisson
          #prior = prior, #our list of pre-defined priors
          #data = new_df.s2,
          #warmup = 500,
          #iter = 1000,
          #cores = 3,
          #chain = 2)

#summary(m1.1)
#plot(m1.1)

#Structure model - model 3
m3_formula <- bf(maxTick ~ outbreakSize + clusteringCoef*pathLength) 


get_prior(m3_formula,new_df.s2)

prior_str = c(prior(normal(log(9.2),log(4.8)), class = Intercept),
              prior(normal(0,0.5), class = b, coef = outbreakSize),
              prior(normal(0,0.5), class = b, coef = clusteringCoef:pathLength))

m3 <- brm(m3_formula,
          family = poisson(link = "log"), 
          prior = prior_str, 
          data = new_df.s2,
          warmup = 4000,
          iter = 10000,
          cores = 3,
          chain = 3)

summary(m3)
plot(m3)
```


```{r}
#Priors and posteriors - plots

#Plot priors
x <- seq(-2,2, length=1e5)
y <- dnorm(x, 0, 0.5)
y.I <- dnorm(x, log(9.2), log(4.8))

prior_df <- data.frame(x = rep(x,1), y = c(y), prior = c(rep("Beta Prior", length(y))))
ggplot(prior_df, aes(x = x, y = y, color = prior)) + geom_line() + ggtitle("Beta Prior")

x <- seq(0,4, length = 1e5)
prior_df <- data.frame(x = rep(x,1), y = c(y.I), prior = c(rep("Intercept Prior", length(y.I))))
ggplot(prior_df, aes(x = x, y = y, color = prior)) + geom_line() + ggtitle("Intercept Prior")

plot(y.I)

#Plot predictive priors

#plot posterior distributions 
  #Model 1
post_samples <- c(posterior_samples(m1)$b_Intercept)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Intercept", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 1: Posterior Distributions - Intercept", x = "Posterior Samples")

post_samples <- c(posterior_samples(m1)$b_outbreakSize)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Outbreak Size", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 1: Posterior Distributions - Outbreak Size", x = "Posterior Samples")

post_samples <- c(posterior_samples(m1)$b_Ratio_WD)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Ratio of Watch Dogs", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 1: Posterior Distributions - Ratio of Watch Dogs", x = "Posterior Samples")

                      
  #Model 3
post_samples <- c(posterior_samples(m2)$b_Intercept)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Intercept", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 3: Posterior Distribution - Intercept", x = "Posterior Samples")


post_samples <- c(posterior_samples(m3)$b_outbreakSize)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("OutbreakSize", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 3: Posterior Distribution - Outbreak Size", x = "Posterior Samples")

post_samples <- c(posterior_samples(m3)$b_clusteringCoef)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Clustering Coefficient", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 3: Posterior Distribution - Clustering Coefficient", x = "Posterior Samples")

post_samples <- c(posterior_samples(m3)$b_pathLength)
post_df <- data.frame(post_samples = post_samples, parameter = c(rep("Average Path Length", 1000)))
ggplot(post_df, aes(x = post_samples, color = parameter)) + geom_density(adjust = 1) + labs(title = "Model 3: Posterior Distribution - Average Path Length", x = "Posterior Samples")

  #compare models with infomation criterion and weights:
waic <- brms::WAIC(m1, m3)
weights <- brms::model_weights(m1, m3, weights = "waic")

  #Predictive posterior
pp_check(m1,nsamples = 200)
pp_check(m3,nsamples = 200)

  #Making sense of estimates - posterior distribtions for estimates
stanplot(m1)
stanplot(m3)


```


